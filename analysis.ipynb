{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "analysis_dir = [\"PATH/TO/CSV/DATA.csv\"]\n",
    "for i in range(len(analysis_dir)):\n",
    "    split_path = analysis_dir[i].split(\"/\")\n",
    "    analysis_dir[i] = os.path.join(*split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_and_create_file(path_file):\n",
    "    with open(path_file, \"r\") as f:\n",
    "        whole = f.readlines()\n",
    "    header = whole[0][:-3].split(\",,\")\n",
    "    unlabeled_full_headers = whole[1][:-2].split(\",\")\n",
    "    assert 2*len(header) == len(unlabeled_full_headers)\n",
    "    \n",
    "    full_headers = []\n",
    "    \n",
    "    for i,cur_head in enumerate(unlabeled_full_headers):\n",
    "        full_headers.append(cur_head+\"_\"+header[i//2])\n",
    "    out_text = \",\".join(full_headers)+\"\\n\" \n",
    "    for i in range(2,len(whole)):\n",
    "        if whole[i].strip() == \"\":\n",
    "            break\n",
    "        out_text+=whole[i][:-2]+\"\\n\"\n",
    "    split_by_dot = path_file.split(\".\")\n",
    "    out_path = split_by_dot[0]+\"_cleaned.\"+split_by_dot[1]\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(out_text)\n",
    "    return out_path\n",
    "    \n",
    "    \n",
    "out_dirs = [cleanup_and_create_file(cur_analysis) for cur_analysis in analysis_dir]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import argrelextrema,find_peaks,find_peaks_cwt\n",
    "from math import ceil\n",
    "from lmfit import Model\n",
    "\n",
    "DONOR = \"Em570\"\n",
    "ACCEPTOR = \"Em667\"\n",
    "\n",
    "fit_model = lambda t,a,b,tau: a*np.exp(-(t)/tau)+b\n",
    "\n",
    "def generate_plot(csv_path_file, donor,acceptor,all_intensity=None):\n",
    "    df = pd.read_csv(csv_path_file)\n",
    "    lowest_cutoff = np.inf\n",
    "    for i in range(0, len(df.columns), 2):\n",
    "        time_col = df.columns[i]\n",
    "        intensity_col = df.columns[i+1]\n",
    "        #if donor in intensity_col:\n",
    "        #    sns.lineplot(x=time_col, y=intensity_col, data=df)\n",
    "        #last_peak = find_peaks(df[intensity_col], threshold=10)[0][-1]\n",
    "        print(find_peaks(df[intensity_col], threshold=10)[0])\n",
    "        peaks = find_peaks_cwt(df[intensity_col], 10,window_size=40,min_snr=1.5)\n",
    "        if len(peaks) == 0:\n",
    "            last_peak = np.inf\n",
    "        else:\n",
    "            last_peak = peaks[-1]\n",
    "        \n",
    "        \n",
    "        #df = df.iloc[find_peaks(df[intensity_col], threshold=10)[0][-1]:,:]\n",
    "        \n",
    "        #df remove first 1% of data\n",
    "        #df = df.iloc[ceil(df.shape[0]*0.01):,:] \n",
    "        \n",
    "        #Line plot with dashed line\n",
    "        \n",
    "        cutoff_point = ceil(2*df.shape[0]/100) + last_peak\n",
    "        \n",
    "        \n",
    "        sns.lineplot(x=time_col, y=intensity_col, data=df[df.index < cutoff_point],linestyle=\"--\")\n",
    "        \n",
    "        sns.lineplot(x=time_col, y=intensity_col, data=df[df.index >= cutoff_point],label=intensity_col)\n",
    "        \n",
    "        #Put locations of peaks on plot\n",
    "        #for cur_peak in peaks:\n",
    "        #    plt.axvline(x=df[time_col].iloc[cur_peak],color=\"black\",linestyle=\"--\")\n",
    "        \n",
    "        if cutoff_point < lowest_cutoff:\n",
    "            lowest_cutoff = cutoff_point\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"Intensity (a.u.)\")\n",
    "    \n",
    "    for cur_col in df.columns:\n",
    "        if \"Intensity\" in cur_col:\n",
    "            if donor in cur_col:\n",
    "                donor_col = cur_col\n",
    "            elif acceptor in cur_col:\n",
    "                acceptor_col = cur_col\n",
    "                \n",
    "        elif \"Time\" in cur_col:\n",
    "            if donor in cur_col:\n",
    "                donor_time = cur_col\n",
    "            elif acceptor in cur_col:\n",
    "                acceptor_time = cur_col\n",
    "    \n",
    "    fret_efficiency = df[acceptor_col] / (df[donor_col]+df[acceptor_col])\n",
    "    fret_time = (df[donor_time] + df[acceptor_time]) / 2\n",
    "    plt.show()\n",
    "    \n",
    "    sns.lineplot(x=fret_time.iloc[lowest_cutoff:], y=fret_efficiency.iloc[lowest_cutoff:])\n",
    "    \n",
    "    valid = ~(np.isnan(fret_efficiency) | np.isnan(fret_time))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #popt,_=curve_fit(fit_model, fret_time[valid], fret_efficiency[valid])\n",
    "    #print(fret_efficiency[valid].iloc[lowest_cutoff:])\n",
    "    emodel = Model(fit_model)\n",
    "    params = emodel.make_params(a=1,b=0,tau=1)\n",
    "    result = emodel.fit(fret_efficiency[valid].iloc[lowest_cutoff:], params, t=fret_time[valid].iloc[lowest_cutoff:])\n",
    "    #Plot the fit model\n",
    "    \n",
    "    #plt.plot(np.arange(0,1000), fit_model(np.arange(0,1000), *popt), 'r-', label='fit')\n",
    "    #print(popt)\n",
    "    print(result.fit_report())\n",
    "    plt.plot(fret_time[valid].iloc[lowest_cutoff:],result.best_fit,label=\"fit\")\n",
    "    plt.ylabel(\"FRET Efficiency\")\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    \n",
    "    #Plot uncertainties as well\n",
    "    perc_95 = result.eval_uncertainty(sigma=2)\n",
    "    plt.fill_between(fret_time[valid].iloc[lowest_cutoff:], result.best_fit-perc_95, result.best_fit+perc_95, color=\"#ABABAB\",\n",
    "                 label='95% confidence interval')\n",
    "    \n",
    "    tau = result.best_values[\"tau\"]\n",
    "    #Plt text of tau, only to 2 decimal places\n",
    "    plt.text(0.5,0.5,r\"$\\tau =$ \"+str(round(tau,3)),transform=plt.gca().transAxes)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    \n",
    "    f_name = os.path.split(csv_path_file)[-1].split(\".\")[0]\n",
    "    \n",
    "    if all_intensity is not None:\n",
    "        for i in range(0, len(df.columns), 2):\n",
    "            time_col = df.columns[i]\n",
    "            intensity_col = df.columns[i+1]\n",
    "            sns.lineplot(x=time_col, y=intensity_col, data=df.iloc[df.index >= lowest_cutoff], label=intensity_col+\"_\"+f_name,ax=all_intensity)\n",
    "        \n",
    "    \n",
    "    return result,lowest_cutoff,fret_efficiency,fret_time\n",
    "        \n",
    "def generate_global_plot(all_csvs, all_cutoffs):\n",
    "    for j,csv in enumerate(all_csvs):\n",
    "        df = pd.read_csv(csv)\n",
    "        \n",
    "        f_name = os.path.split(csv)[-1].split(\".\")[0]\n",
    "        \n",
    "        for i in range(0, len(df.columns), 2):\n",
    "            time_col = df.columns[i]\n",
    "            intensity_col = df.columns[i+1]\n",
    "            sns.lineplot(x=time_col, y=intensity_col, data=df.iloc[df.index >= all_cutoffs[j]], label=intensity_col+\"_\"+f_name)\n",
    "    plt.savefig(\"global_plot.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "def tau_compare(all_csvs,taus):\n",
    "    names = [os.path.split(csv)[-1].split(\".\")[0 ]for csv in all_csvs]\n",
    "    \n",
    "    df = pd.DataFrame({\"Name\":names,\"Tau\":taus})\n",
    "    df[\"Unwinding\"] = 1/ (df[\"Tau\"] * 60)\n",
    "    sns.barplot(x=\"Name\",y=\"Tau\",data=df)\n",
    "    plt.savefig(\"tau_compare.png\")\n",
    "    plt.clf()\n",
    "    sns.barplot(x=\"Name\",y=\"Unwinding\",data=df)\n",
    "    plt.savefig(\"unwinding_compare.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "def fret_compare(all_csvs,fes,fts,all_cutoffs):\n",
    "    names = [os.path.split(csv)[-1].split(\".\")[0 ]for csv in all_csvs]\n",
    "    for i,(ft,fe) in enumerate(zip(fts,fes)):\n",
    "        sns.lineplot(x=ft.iloc[all_cutoffs[i]:],y=fe.iloc[all_cutoffs[i]:],label=names[i])\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"FRET Efficiency\")\n",
    "    plt.savefig(\"fret_compare.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "        \n",
    "fig,all_intensity = plt.subplots(1,1)\n",
    "all_cutoffs = []\n",
    "taus = []\n",
    "fes = []\n",
    "fts = []\n",
    "for out_dir in out_dirs:\n",
    "    fit_result,lowest_cutoff,fret_efficiency,fret_time = generate_plot(out_dir, DONOR, ACCEPTOR,all_intensity)\n",
    "    all_cutoffs.append(lowest_cutoff)\n",
    "    taus.append(fit_result.best_values[\"tau\"])\n",
    "    fes.append(fret_efficiency)\n",
    "    fts.append(fret_time)\n",
    "\n",
    "generate_global_plot(out_dirs, all_cutoffs)\n",
    "tau_compare(out_dirs,taus)\n",
    "fret_compare(out_dirs,fes,fts,all_cutoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
